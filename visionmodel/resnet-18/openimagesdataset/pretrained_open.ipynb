{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYlcpI1nP4by",
        "outputId": "78a6908d-0b89-470f-8be1-f1dc09b1b134"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: fiftyone in /usr/local/lib/python3.12/dist-packages (1.11.0)\n",
            "Requirement already satisfied: aiofiles in /usr/local/lib/python3.12/dist-packages (from fiftyone) (24.1.0)\n",
            "Requirement already satisfied: argcomplete in /usr/local/lib/python3.12/dist-packages (from fiftyone) (3.6.3)\n",
            "Requirement already satisfied: async_lru>=2 in /usr/local/lib/python3.12/dist-packages (from fiftyone) (2.0.5)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from fiftyone) (4.13.5)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.12/dist-packages (from fiftyone) (1.42.9)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.12/dist-packages (from fiftyone) (6.2.2)\n",
            "Requirement already satisfied: dacite<2,>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from fiftyone) (1.9.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from fiftyone) (0.3.8)\n",
            "Requirement already satisfied: Deprecated in /usr/local/lib/python3.12/dist-packages (from fiftyone) (1.3.1)\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.12/dist-packages (from fiftyone) (6.3.1)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.12/dist-packages (from fiftyone) (4.14.0)\n",
            "Requirement already satisfied: hypercorn>=0.13.2 in /usr/local/lib/python3.12/dist-packages (from fiftyone) (0.18.0)\n",
            "Requirement already satisfied: Jinja2>=3 in /usr/local/lib/python3.12/dist-packages (from fiftyone) (3.1.6)\n",
            "Requirement already satisfied: jsonpatch in /usr/local/lib/python3.12/dist-packages (from fiftyone) (1.33)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from fiftyone) (3.10.0)\n",
            "Requirement already satisfied: mongoengine~=0.29.1 in /usr/local/lib/python3.12/dist-packages (from fiftyone) (0.29.1)\n",
            "Requirement already satisfied: motor~=3.6.0 in /usr/local/lib/python3.12/dist-packages (from fiftyone) (3.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from fiftyone) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from fiftyone) (25.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from fiftyone) (2.2.2)\n",
            "Requirement already satisfied: Pillow!=11.2.*,>=6.2 in /usr/local/lib/python3.12/dist-packages (from fiftyone) (11.3.0)\n",
            "Requirement already satisfied: plotly>=6.1.1 in /usr/local/lib/python3.12/dist-packages (from fiftyone) (6.5.0)\n",
            "Requirement already satisfied: pprintpp in /usr/local/lib/python3.12/dist-packages (from fiftyone) (0.4.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from fiftyone) (5.9.5)\n",
            "Requirement already satisfied: pymongo~=4.9.2 in /usr/local/lib/python3.12/dist-packages (from fiftyone) (4.9.2)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.12/dist-packages (from fiftyone) (2025.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from fiftyone) (6.0.3)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.12/dist-packages (from fiftyone) (2025.11.3)\n",
            "Requirement already satisfied: retrying in /usr/local/lib/python3.12/dist-packages (from fiftyone) (1.4.2)\n",
            "Requirement already satisfied: rtree in /usr/local/lib/python3.12/dist-packages (from fiftyone) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from fiftyone) (1.6.1)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.12/dist-packages (from fiftyone) (0.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from fiftyone) (1.16.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from fiftyone) (75.2.0)\n",
            "Requirement already satisfied: sseclient-py<2,>=1.7.2 in /usr/local/lib/python3.12/dist-packages (from fiftyone) (1.8.0)\n",
            "Requirement already satisfied: sse-starlette<1,>=0.10.3 in /usr/local/lib/python3.12/dist-packages (from fiftyone) (0.10.3)\n",
            "Requirement already satisfied: starlette>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from fiftyone) (0.48.0)\n",
            "Requirement already satisfied: strawberry-graphql>=0.262.4 in /usr/local/lib/python3.12/dist-packages (from fiftyone) (0.287.3)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.12/dist-packages (from fiftyone) (0.9.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from fiftyone) (4.67.1)\n",
            "Requirement already satisfied: xmltodict in /usr/local/lib/python3.12/dist-packages (from fiftyone) (1.0.2)\n",
            "Requirement already satisfied: universal-analytics-python3<2,>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from fiftyone) (1.1.1)\n",
            "Requirement already satisfied: pydash in /usr/local/lib/python3.12/dist-packages (from fiftyone) (8.0.5)\n",
            "Requirement already satisfied: fiftyone-brain<0.22,>=0.21.4 in /usr/local/lib/python3.12/dist-packages (from fiftyone) (0.21.4)\n",
            "Requirement already satisfied: fiftyone-db<2.0,>=0.4 in /usr/local/lib/python3.12/dist-packages (from fiftyone) (1.4.0)\n",
            "Requirement already satisfied: voxel51-eta<0.16,>=0.15.1 in /usr/local/lib/python3.12/dist-packages (from fiftyone) (0.15.1)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.12/dist-packages (from fiftyone) (4.12.0.88)\n",
            "Requirement already satisfied: h11 in /usr/local/lib/python3.12/dist-packages (from hypercorn>=0.13.2->fiftyone) (0.16.0)\n",
            "Requirement already satisfied: h2>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from hypercorn>=0.13.2->fiftyone) (4.3.0)\n",
            "Requirement already satisfied: priority in /usr/local/lib/python3.12/dist-packages (from hypercorn>=0.13.2->fiftyone) (2.0.0)\n",
            "Requirement already satisfied: wsproto>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from hypercorn>=0.13.2->fiftyone) (1.3.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from Jinja2>=3->fiftyone) (3.0.3)\n",
            "Requirement already satisfied: narwhals>=1.15.1 in /usr/local/lib/python3.12/dist-packages (from plotly>=6.1.1->fiftyone) (2.13.0)\n",
            "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.12/dist-packages (from pymongo~=4.9.2->fiftyone) (2.8.0)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.12/dist-packages (from starlette>=0.24.0->fiftyone) (4.12.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from starlette>=0.24.0->fiftyone) (4.15.0)\n",
            "Requirement already satisfied: graphql-core<3.4.0,>=3.2.0 in /usr/local/lib/python3.12/dist-packages (from strawberry-graphql>=0.262.4->fiftyone) (3.2.7)\n",
            "Requirement already satisfied: lia-web>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from strawberry-graphql>=0.262.4->fiftyone) (0.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from strawberry-graphql>=0.262.4->fiftyone) (2.9.0.post0)\n",
            "Requirement already satisfied: httpx>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from universal-analytics-python3<2,>=1.0.1->fiftyone) (0.28.1)\n",
            "Requirement already satisfied: glob2 in /usr/local/lib/python3.12/dist-packages (from voxel51-eta<0.16,>=0.15.1->fiftyone) (0.7)\n",
            "Requirement already satisfied: jsonlines in /usr/local/lib/python3.12/dist-packages (from voxel51-eta<0.16,>=0.15.1->fiftyone) (4.0.0)\n",
            "Requirement already satisfied: paramiko<4,>=3 in /usr/local/lib/python3.12/dist-packages (from voxel51-eta<0.16,>=0.15.1->fiftyone) (3.5.1)\n",
            "Requirement already satisfied: py7zr in /usr/local/lib/python3.12/dist-packages (from voxel51-eta<0.16,>=0.15.1->fiftyone) (1.0.0)\n",
            "Requirement already satisfied: rarfile in /usr/local/lib/python3.12/dist-packages (from voxel51-eta<0.16,>=0.15.1->fiftyone) (4.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from voxel51-eta<0.16,>=0.15.1->fiftyone) (2.32.4)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.12/dist-packages (from voxel51-eta<0.16,>=0.15.1->fiftyone) (2.4.0)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.12/dist-packages (from voxel51-eta<0.16,>=0.15.1->fiftyone) (5.3.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.12/dist-packages (from voxel51-eta<0.16,>=0.15.1->fiftyone) (2.5.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->fiftyone) (2.8)\n",
            "Requirement already satisfied: botocore<1.43.0,>=1.42.9 in /usr/local/lib/python3.12/dist-packages (from boto3->fiftyone) (1.42.9)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from boto3->fiftyone) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.17.0,>=0.16.0 in /usr/local/lib/python3.12/dist-packages (from boto3->fiftyone) (0.16.0)\n",
            "Requirement already satisfied: wrapt<3,>=1.10 in /usr/local/lib/python3.12/dist-packages (from Deprecated->fiftyone) (2.0.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from ftfy->fiftyone) (0.2.14)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch->fiftyone) (3.0.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->fiftyone) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->fiftyone) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->fiftyone) (4.61.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->fiftyone) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->fiftyone) (3.2.5)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->fiftyone) (2025.2)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from scikit-image->fiftyone) (3.6.1)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.12/dist-packages (from scikit-image->fiftyone) (2.37.2)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image->fiftyone) (2025.10.16)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image->fiftyone) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->fiftyone) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->fiftyone) (3.6.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.6.2->starlette>=0.24.0->fiftyone) (3.11)\n",
            "Requirement already satisfied: hyperframe<7,>=6.1 in /usr/local/lib/python3.12/dist-packages (from h2>=4.3.0->hypercorn>=0.13.2->fiftyone) (6.1.0)\n",
            "Requirement already satisfied: hpack<5,>=4.1 in /usr/local/lib/python3.12/dist-packages (from h2>=4.3.0->hypercorn>=0.13.2->fiftyone) (4.1.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.10.0->universal-analytics-python3<2,>=1.0.1->fiftyone) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.10.0->universal-analytics-python3<2,>=1.0.1->fiftyone) (1.0.9)\n",
            "Requirement already satisfied: bcrypt>=3.2 in /usr/local/lib/python3.12/dist-packages (from paramiko<4,>=3->voxel51-eta<0.16,>=0.15.1->fiftyone) (5.0.0)\n",
            "Requirement already satisfied: cryptography>=3.3 in /usr/local/lib/python3.12/dist-packages (from paramiko<4,>=3->voxel51-eta<0.16,>=0.15.1->fiftyone) (43.0.3)\n",
            "Requirement already satisfied: pynacl>=1.5 in /usr/local/lib/python3.12/dist-packages (from paramiko<4,>=3->voxel51-eta<0.16,>=0.15.1->fiftyone) (1.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->strawberry-graphql>=0.262.4->fiftyone) (1.17.0)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonlines->voxel51-eta<0.16,>=0.15.1->fiftyone) (25.4.0)\n",
            "Requirement already satisfied: texttable in /usr/local/lib/python3.12/dist-packages (from py7zr->voxel51-eta<0.16,>=0.15.1->fiftyone) (1.7.0)\n",
            "Requirement already satisfied: pycryptodomex>=3.20.0 in /usr/local/lib/python3.12/dist-packages (from py7zr->voxel51-eta<0.16,>=0.15.1->fiftyone) (3.23.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from py7zr->voxel51-eta<0.16,>=0.15.1->fiftyone) (1.2.0)\n",
            "Requirement already satisfied: pyzstd>=0.16.1 in /usr/local/lib/python3.12/dist-packages (from py7zr->voxel51-eta<0.16,>=0.15.1->fiftyone) (0.19.1)\n",
            "Requirement already satisfied: pyppmd<1.3.0,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from py7zr->voxel51-eta<0.16,>=0.15.1->fiftyone) (1.2.0)\n",
            "Requirement already satisfied: pybcj<1.1.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from py7zr->voxel51-eta<0.16,>=0.15.1->fiftyone) (1.0.7)\n",
            "Requirement already satisfied: multivolumefile>=0.2.3 in /usr/local/lib/python3.12/dist-packages (from py7zr->voxel51-eta<0.16,>=0.15.1->fiftyone) (0.2.3)\n",
            "Requirement already satisfied: inflate64<1.1.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from py7zr->voxel51-eta<0.16,>=0.15.1->fiftyone) (1.0.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->voxel51-eta<0.16,>=0.15.1->fiftyone) (3.4.4)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=3.3->paramiko<4,>=3->voxel51-eta<0.16,>=0.15.1->fiftyone) (2.0.0)\n",
            "Requirement already satisfied: backports-zstd>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from pyzstd>=0.16.1->py7zr->voxel51-eta<0.16,>=0.15.1->fiftyone) (1.2.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=3.3->paramiko<4,>=3->voxel51-eta<0.16,>=0.15.1->fiftyone) (2.23)\n"
          ]
        }
      ],
      "source": [
        "!pip install fiftyone\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFS4oefRSsD_"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSqZPLwqRY1l",
        "outputId": "324501b9-207c-4435-854b-810537d6adbf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading split 'train' to '/root/fiftyone/open-images-v7/train' if necessary\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:fiftyone.zoo.datasets:Downloading split 'train' to '/root/fiftyone/open-images-v7/train' if necessary\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading 10000 images\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:fiftyone.utils.openimages:Downloading 10000 images\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 100% |███████████████| 10000/10000 [19.9m elapsed, 0s remaining, 7.3 files/s]      \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:eta.core.utils: 100% |███████████████| 10000/10000 [19.9m elapsed, 0s remaining, 7.3 files/s]      \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset info written to '/root/fiftyone/open-images-v7/info.json'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:fiftyone.zoo.datasets:Dataset info written to '/root/fiftyone/open-images-v7/info.json'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading 'open-images-v7' split 'train'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:fiftyone.zoo.datasets:Loading 'open-images-v7' split 'train'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 100% |█████████████| 10000/10000 [55.9s elapsed, 0s remaining, 173.1 samples/s]      \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:eta.core.utils: 100% |█████████████| 10000/10000 [55.9s elapsed, 0s remaining, 173.1 samples/s]      \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset 'open-images-food-train' created\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:fiftyone.zoo.datasets:Dataset 'open-images-food-train' created\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading split 'validation' to '/root/fiftyone/open-images-v7/validation' if necessary\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:fiftyone.zoo.datasets:Downloading split 'validation' to '/root/fiftyone/open-images-v7/validation' if necessary\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading 'https://storage.googleapis.com/openimages/2018_04/validation/validation-images-with-rotation.csv' to '/root/fiftyone/open-images-v7/validation/metadata/image_ids.csv'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:fiftyone.utils.openimages:Downloading 'https://storage.googleapis.com/openimages/2018_04/validation/validation-images-with-rotation.csv' to '/root/fiftyone/open-images-v7/validation/metadata/image_ids.csv'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading 'https://storage.googleapis.com/openimages/v5/class-descriptions-boxable.csv' to '/root/fiftyone/open-images-v7/validation/metadata/classes.csv'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:fiftyone.utils.openimages:Downloading 'https://storage.googleapis.com/openimages/v5/class-descriptions-boxable.csv' to '/root/fiftyone/open-images-v7/validation/metadata/classes.csv'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading 'https://storage.googleapis.com/openimages/2018_04/bbox_labels_600_hierarchy.json' to '/tmp/tmpg7d7b19y/metadata/hierarchy.json'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:fiftyone.utils.openimages:Downloading 'https://storage.googleapis.com/openimages/2018_04/bbox_labels_600_hierarchy.json' to '/tmp/tmpg7d7b19y/metadata/hierarchy.json'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading 'https://storage.googleapis.com/openimages/v5/validation-annotations-bbox.csv' to '/root/fiftyone/open-images-v7/validation/labels/detections.csv'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:fiftyone.utils.openimages:Downloading 'https://storage.googleapis.com/openimages/v5/validation-annotations-bbox.csv' to '/root/fiftyone/open-images-v7/validation/labels/detections.csv'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Only found 1781 (<2000) samples matching your requirements\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:fiftyone.utils.openimages:Only found 1781 (<2000) samples matching your requirements\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading 1781 images\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:fiftyone.utils.openimages:Downloading 1781 images\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 100% |█████████████████| 1781/1781 [3.7m elapsed, 0s remaining, 8.5 files/s]       \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:eta.core.utils: 100% |█████████████████| 1781/1781 [3.7m elapsed, 0s remaining, 8.5 files/s]       \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset info written to '/root/fiftyone/open-images-v7/info.json'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:fiftyone.zoo.datasets:Dataset info written to '/root/fiftyone/open-images-v7/info.json'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading 'open-images-v7' split 'validation'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:fiftyone.zoo.datasets:Loading 'open-images-v7' split 'validation'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 100% |███████████████| 1781/1781 [11.2s elapsed, 0s remaining, 169.1 samples/s]      \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:eta.core.utils: 100% |███████████████| 1781/1781 [11.2s elapsed, 0s remaining, 169.1 samples/s]      \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset 'open-images-food-validation' created\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:fiftyone.zoo.datasets:Dataset 'open-images-food-validation' created\n"
          ]
        }
      ],
      "source": [
        "#second dataset download here\n",
        "\n",
        "import fiftyone as fo\n",
        "import fiftyone.zoo as foz\n",
        "\n",
        "FOOD_CLASSES = [\n",
        "    \"Apple\", \"Banana\", \"Bell pepper\", \"Bread\", \"Cabbage\", \"Cake\",\n",
        "    \"Carrot\", \"Cheese\", \"Chicken\", \"Ice cream\", \"Orange\",\n",
        "    \"Pizza\", \"Potato\", \"Salad\", \"Shrimp\", \"Taco\", \"Tomato\",\n",
        "    \"Watermelon\", \"French fries\", \"Hamburger\", \"Pasta\",\n",
        "    \"Grape\", \"Peach\", \"Pear\"\n",
        "]\n",
        "\n",
        "\n",
        "# Download the training split of Open Images V7, filtering for your classes\n",
        "train_dataset = foz.load_zoo_dataset(\n",
        "    \"open-images-v7\",\n",
        "    split=\"train\",\n",
        "    label_types=[\"detections\"],\n",
        "    classes=FOOD_CLASSES,\n",
        "    # Optional: limit the number of samples for a quicker start\n",
        "    max_samples=10000,\n",
        "    dataset_name=\"open-images-food-train\",\n",
        ")\n",
        "\n",
        "# Download the validation split\n",
        "val_dataset = foz.load_zoo_dataset(\n",
        "    \"open-images-v7\",\n",
        "    split=\"validation\",\n",
        "    label_types=[\"detections\"],\n",
        "    classes=FOOD_CLASSES,\n",
        "    max_samples=2000,\n",
        "    dataset_name=\"open-images-food-validation\",\n",
        ")\n",
        "\n",
        "# You can launch the FiftyOne App to visualize and further curate your data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4oZhAWDRaOy",
        "outputId": "bfceb95e-185a-4601-e655-637900092936"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "graphviz is already the newest version (2.42.2-6ubuntu0.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 41 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!pip install -q wandb torchviz fvcore grad-cam scikit-learn graphviz\n",
        "!apt-get -q install graphviz\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-Iw2J_EZKpS",
        "outputId": "0aebe323-0176-4d94-ef17-4fa4aa614db5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train samples after filtering: 10000\n",
            "Val samples after filtering: 1781\n"
          ]
        }
      ],
      "source": [
        "import fiftyone as fo\n",
        "\n",
        "def convert_to_classification(dataset, food_classes, name):\n",
        "    new_ds = fo.Dataset(name=name)\n",
        "\n",
        "    for sample in dataset:\n",
        "        if \"ground_truth\" not in sample:\n",
        "            continue\n",
        "\n",
        "        labels = [\n",
        "            det.label\n",
        "            for det in sample.ground_truth.detections\n",
        "            if det.label in food_classes\n",
        "        ]\n",
        "\n",
        "        if not labels:\n",
        "            continue\n",
        "\n",
        "        sample[\"cls\"] = fo.Classification(label=labels[0])\n",
        "        new_ds.add_sample(sample)\n",
        "\n",
        "    return new_ds\n",
        "\n",
        "\n",
        "# Load the datasets\n",
        "train_raw = fo.load_dataset(\"open-images-food-train\")\n",
        "val_raw   = fo.load_dataset(\"open-images-food-validation\")\n",
        "\n",
        "# Convert to classification\n",
        "train_cls = convert_to_classification(\n",
        "    train_raw, FOOD_CLASSES, \"open-images-food-train-cls\"\n",
        ")\n",
        "\n",
        "val_cls = convert_to_classification(\n",
        "    val_raw, FOOD_CLASSES, \"open-images-food-val-cls\"\n",
        ")\n",
        "\n",
        "print(\"Train samples after filtering:\", len(train_cls))\n",
        "print(\"Val samples after filtering:\", len(val_cls))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9qXTyzN2ZjJ7",
        "outputId": "72ea0f5e-fbe9-4eb1-c89a-c5d7bf7637f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 100% |█████████████| 10000/10000 [58.9s elapsed, 0s remaining, 219.6 samples/s]      \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:eta.core.utils: 100% |█████████████| 10000/10000 [58.9s elapsed, 0s remaining, 219.6 samples/s]      \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 100% |███████████████| 1781/1781 [7.9s elapsed, 0s remaining, 194.2 samples/s]      \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:eta.core.utils: 100% |███████████████| 1781/1781 [7.9s elapsed, 0s remaining, 194.2 samples/s]      \n"
          ]
        }
      ],
      "source": [
        "train_cls.export(\n",
        "    export_dir=\"/content/openimages_classification/train\",\n",
        "    dataset_type=fo.types.ImageClassificationDirectoryTree,\n",
        "    label_field=\"cls\"\n",
        ")\n",
        "\n",
        "val_cls.export(\n",
        "    export_dir=\"/content/openimages_classification/val\",\n",
        "    dataset_type=fo.types.ImageClassificationDirectoryTree,\n",
        "    label_field=\"cls\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cXVAsdWKfua",
        "outputId": "f79e534a-55e3-4830-fe78-2d51b0312c79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train images: 10000\n",
            "Val images: 1781\n",
            "Classes: 24\n",
            "['Apple', 'Banana', 'Bell pepper', 'Bread', 'Cabbage', 'Cake', 'Carrot', 'Cheese', 'Chicken', 'French fries', 'Grape', 'Hamburger', 'Ice cream', 'Orange', 'Pasta', 'Peach', 'Pear', 'Pizza', 'Potato', 'Salad', 'Shrimp', 'Taco', 'Tomato', 'Watermelon']\n"
          ]
        }
      ],
      "source": [
        "from torchvision import datasets\n",
        "\n",
        "train_full = datasets.ImageFolder(\"/content/openimages_classification/train\")\n",
        "val_full   = datasets.ImageFolder(\"/content/openimages_classification/val\")\n",
        "\n",
        "print(\"Train images:\", len(train_full))\n",
        "print(\"Val images:\", len(val_full))\n",
        "print(\"Classes:\", len(train_full.classes))\n",
        "print(train_full.classes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y4ju8I1EVLq4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"TORCH_COMPILE_DISABLE\"] = \"1\"\n",
        "os.environ[\"TORCHINDUCTOR_DISABLE\"] = \"1\"\n",
        "os.environ[\"TORCH_LOGS\"] = \"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "0Jt973tLpq5u",
        "outputId": "69910340-147d-4374-d5d6-09915ad6698f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
            "  | |_| | '_ \\/ _` / _` |  _/ -_)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose 'Use an existing W&B account'\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into https://api.wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find your API key here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrashvin-rajanah-23\u001b[0m (\u001b[33mrashvin-rajanah-23-ucl\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.23.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251214_161841-ijt1ym2o</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/rashvin-rajanah-23-ucl/vision-cw/runs/ijt1ym2o' target=\"_blank\">resnet-openimages</a></strong> to <a href='https://wandb.ai/rashvin-rajanah-23-ucl/vision-cw' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/rashvin-rajanah-23-ucl/vision-cw' target=\"_blank\">https://wandb.ai/rashvin-rajanah-23-ucl/vision-cw</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/rashvin-rajanah-23-ucl/vision-cw/runs/ijt1ym2o' target=\"_blank\">https://wandb.ai/rashvin-rajanah-23-ucl/vision-cw/runs/ijt1ym2o</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/rashvin-rajanah-23-ucl/vision-cw/runs/ijt1ym2o?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7b933301bad0>"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import wandb\n",
        "wandb.login()\n",
        "\n",
        "wandb.init(\n",
        "    project=\"vision-cw\",\n",
        "    name=\"resnet-openimages\",\n",
        "    config={\n",
        "        \"dataset\": \"openimages\",\n",
        "        \"augmentation\": True,\n",
        "        \"epochs\": 30,\n",
        "        \"batch_size\": 32,\n",
        "        \"lr\": 1e-3\n",
        "    }\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZcH9LRzFWnNw",
        "outputId": "93bc67a5-03b0-4755-e5fb-099754535b2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running on: cuda\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.23.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251214_171007-sinvkiz1</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/rashvin-rajanah-23-ucl/vision-cw/runs/sinvkiz1' target=\"_blank\">resnet18_pretrained_openimages</a></strong> to <a href='https://wandb.ai/rashvin-rajanah-23-ucl/vision-cw' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/rashvin-rajanah-23-ucl/vision-cw' target=\"_blank\">https://wandb.ai/rashvin-rajanah-23-ucl/vision-cw</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/rashvin-rajanah-23-ucl/vision-cw/runs/sinvkiz1' target=\"_blank\">https://wandb.ai/rashvin-rajanah-23-ucl/vision-cw/runs/sinvkiz1</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classes: 24\n",
            "Training images (pretrained): 10000\n",
            "Validation images:            1781\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [02:35<00:00,  2.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1: TrainAcc=0.634 ValAcc=0.718\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [02:35<00:00,  2.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2: TrainAcc=0.862 ValAcc=0.736\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [02:35<00:00,  2.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3: TrainAcc=0.960 ValAcc=0.741\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [02:35<00:00,  2.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4: TrainAcc=0.994 ValAcc=0.766\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [02:36<00:00,  2.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5: TrainAcc=0.996 ValAcc=0.752\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [02:35<00:00,  2.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6: TrainAcc=0.996 ValAcc=0.733\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [02:35<00:00,  2.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7: TrainAcc=0.999 ValAcc=0.762\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [02:34<00:00,  2.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8: TrainAcc=1.000 ValAcc=0.757\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [02:35<00:00,  2.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9: TrainAcc=0.998 ValAcc=0.673\n",
            "Macro F1: 0.7411628000956766\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▄▅▅▆▇█</td></tr><tr><td>macro_f1</td><td>▁</td></tr><tr><td>num_classes</td><td>▁</td></tr><tr><td>train_acc</td><td>▁▅▇██████</td></tr><tr><td>train_images</td><td>▁</td></tr><tr><td>train_loss</td><td>█▄▂▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▄▆▆█▇▅█▇▁</td></tr><tr><td>val_images</td><td>▁</td></tr><tr><td>val_loss</td><td>▂▁▂▁▂▃▃▃█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>9</td></tr><tr><td>macro_f1</td><td>0.74116</td></tr><tr><td>num_classes</td><td>24</td></tr><tr><td>train_acc</td><td>0.9984</td></tr><tr><td>train_images</td><td>10000</td></tr><tr><td>train_loss</td><td>0.01333</td></tr><tr><td>val_acc</td><td>0.67266</td></tr><tr><td>val_images</td><td>1781</td></tr><tr><td>val_loss</td><td>1.70101</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">resnet18_pretrained_openimages</strong> at: <a href='https://wandb.ai/rashvin-rajanah-23-ucl/vision-cw/runs/sinvkiz1' target=\"_blank\">https://wandb.ai/rashvin-rajanah-23-ucl/vision-cw/runs/sinvkiz1</a><br> View project at: <a href='https://wandb.ai/rashvin-rajanah-23-ucl/vision-cw' target=\"_blank\">https://wandb.ai/rashvin-rajanah-23-ucl/vision-cw</a><br>Synced 5 W&B file(s), 3 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20251214_171007-sinvkiz1/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "import os, random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from torchvision import datasets, transforms, models\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "\n",
        "from sklearn.metrics import f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
        "from pytorch_grad_cam import GradCAM\n",
        "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
        "\n",
        "import wandb\n",
        "\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Running on:\", device)\n",
        "\n",
        "OUT_DIR = \"/content/outputs\"\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "wandb.init(\n",
        "    project=\"vision-cw\",\n",
        "    name=\"resnet18_pretrained_openimages\"\n",
        ")\n",
        "\n",
        "\n",
        "train_path = \"/content/openimages_classification/train\"\n",
        "val_path   = \"/content/openimages_classification/val\"\n",
        "\n",
        "\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std =[0.229, 0.224, 0.225]\n",
        "    )\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std =[0.229, 0.224, 0.225]\n",
        "    )\n",
        "])\n",
        "\n",
        "\n",
        "train_full = datasets.ImageFolder(train_path, transform=train_transform)\n",
        "val_full   = datasets.ImageFolder(val_path, transform=val_transform)\n",
        "\n",
        "num_classes = len(train_full.classes)\n",
        "print(\"Classes:\", num_classes)\n",
        "\n",
        "train_dataset = train_full\n",
        "val_dataset   = val_full\n",
        "\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader   = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "print(f\"Training images (pretrained): {len(train_dataset)}\")\n",
        "print(f\"Validation images:            {len(val_dataset)}\")\n",
        "\n",
        "wandb.log({\n",
        "    \"train_images\": len(train_dataset),\n",
        "    \"val_images\": len(val_dataset),\n",
        "    \"num_classes\": num_classes\n",
        "})\n",
        "\n",
        "\n",
        "model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
        "\n",
        "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "EPOCHS = 30\n",
        "best_val_loss = float(\"inf\")\n",
        "patience, wait = 5, 0\n",
        "\n",
        "train_losses, val_losses = [], []\n",
        "train_accs, val_accs = [], []\n",
        "\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    correct, total, running_loss = 0, 0, 0\n",
        "\n",
        "    for x, y in tqdm(train_loader):\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        out = model(x)\n",
        "        loss = criterion(out, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        correct += (out.argmax(1) == y).sum().item()\n",
        "        total += y.size(0)\n",
        "\n",
        "    train_loss = running_loss / len(train_loader)\n",
        "    train_acc = correct / total\n",
        "\n",
        "    model.eval()\n",
        "    v_loss, v_correct, v_total = 0, 0, 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in val_loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            out = model(x)\n",
        "            v_loss += criterion(out, y).item()\n",
        "            v_correct += (out.argmax(1) == y).sum().item()\n",
        "            v_total += y.size(0)\n",
        "\n",
        "    val_loss = v_loss / len(val_loader)\n",
        "    val_acc = v_correct / v_total\n",
        "\n",
        "    train_losses.append(train_loss)\n",
        "    val_losses.append(val_loss)\n",
        "    train_accs.append(train_acc)\n",
        "    val_accs.append(val_acc)\n",
        "\n",
        "    wandb.log({\n",
        "        \"epoch\": epoch + 1,\n",
        "        \"train_loss\": train_loss,\n",
        "        \"val_loss\": val_loss,\n",
        "        \"train_acc\": train_acc,\n",
        "        \"val_acc\": val_acc\n",
        "    })\n",
        "\n",
        "    print(f\"Epoch {epoch+1}: TrainAcc={train_acc:.3f} ValAcc={val_acc:.3f}\")\n",
        "\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        torch.save(model.state_dict(), f\"{OUT_DIR}/best_model_pretrained.pth\")\n",
        "        wait = 0\n",
        "    else:\n",
        "        wait += 1\n",
        "        if wait >= patience:\n",
        "            break\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.subplot(1,2,1); plt.plot(train_losses); plt.plot(val_losses); plt.title(\"Loss\")\n",
        "plt.subplot(1,2,2); plt.plot(train_accs); plt.plot(val_accs); plt.title(\"Accuracy\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"{OUT_DIR}/training_curves.jpg\", dpi=300)\n",
        "plt.close()\n",
        "\n",
        "wandb.log({\"training_curves\": wandb.Image(f\"{OUT_DIR}/training_curves.jpg\")})\n",
        "\n",
        "\n",
        "model.load_state_dict(torch.load(f\"{OUT_DIR}/best_model_pretrained.pth\", map_location=device))\n",
        "model.eval()\n",
        "\n",
        "\n",
        "y_true, y_pred = [], []\n",
        "with torch.no_grad():\n",
        "    for x, y in val_loader:\n",
        "        preds = model(x.to(device)).argmax(1)\n",
        "        y_true.extend(y.numpy())\n",
        "        y_pred.extend(preds.cpu().numpy())\n",
        "\n",
        "f1 = f1_score(y_true, y_pred, average=\"macro\")\n",
        "print(\"Macro F1:\", f1)\n",
        "wandb.log({\"macro_f1\": f1})\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred, normalize=\"true\")\n",
        "ConfusionMatrixDisplay(cm).plot(cmap=\"Blues\")\n",
        "plt.savefig(f\"{OUT_DIR}/confusion_matrix.jpg\", dpi=300)\n",
        "plt.close()\n",
        "\n",
        "wandb.log({\"confusion_matrix\": wandb.Image(f\"{OUT_DIR}/confusion_matrix.jpg\")})\n",
        "\n",
        "\n",
        "img_path = val_full.imgs[0][0]\n",
        "img = Image.open(img_path).resize((224,224)).convert(\"RGB\")\n",
        "img_np = np.array(img) / 255.0\n",
        "tensor = val_transform(img).unsqueeze(0).to(device)\n",
        "\n",
        "cam = GradCAM(model=model, target_layers=[model.layer4[-1]])\n",
        "heatmap = cam(input_tensor=tensor)[0]\n",
        "vis = show_cam_on_image(img_np, heatmap, use_rgb=True)\n",
        "\n",
        "plt.imshow(vis); plt.axis(\"off\")\n",
        "plt.savefig(f\"{OUT_DIR}/gradcam.jpg\", dpi=300)\n",
        "plt.close()\n",
        "\n",
        "wandb.log({\"gradcam\": wandb.Image(f\"{OUT_DIR}/gradcam.jpg\")})\n",
        "\n",
        "wandb.finish()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "uSzElkiIahzu",
        "outputId": "1300b6b3-48cb-40f5-923e-98d74099218b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running on: cuda\n",
            "Number of classes: 24\n",
            "✅ Loaded pretrained ResNet-18 weights from /content/outputs/best_model_pretrained.pth\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Sample larger than population or is negative",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-847204217.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_VAL_TEST\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0mclean_ds\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mSubset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVAL_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclean_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/random.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, population, k, counts)\u001b[0m\n\u001b[1;32m    428\u001b[0m         \u001b[0mrandbelow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_randbelow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Sample larger than population or is negative\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m         \u001b[0msetsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m21\u001b[0m        \u001b[0;31m# size of a small set minus size of an empty list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Sample larger than population or is negative"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X701gXBuHGO9",
        "outputId": "0d5a3953-00ab-44ad-8d62-4e97c7768b9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved to /content/outputs/resnet18_architecture.png\n"
          ]
        }
      ],
      "source": [
        "from torchviz import make_dot\n",
        "import torch\n",
        "from torchvision import models\n",
        "\n",
        "model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
        "dummy = torch.randn(1, 3, 224, 224)\n",
        "\n",
        "dot = make_dot(model(dummy), params=dict(model.named_parameters()))\n",
        "dot.format = \"png\"\n",
        "dot.render(\"/content/outputs/resnet18_architecture\")\n",
        "\n",
        "print(\"Saved to /content/outputs/resnet18_architecture.png\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
